var documenterSearchIndex = {"docs":
[{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"EditURL = \"https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_linear_regression.jl\"","category":"page"},{"location":"example_linear_regression/#Linear-regression","page":"Linear regression","title":"Linear regression","text":"","category":"section"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"We estimate simple linear regression model with a half-T prior. First, we load the packages we use.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"using TransformVariables, LogDensityProblems, DynamicHMC, DynamicHMC.Diagnostics,\n    Parameters, Statistics, Random, Distributions, TransformedLogDensities\nusing MCMCDiagnostics\nimport ForwardDiff              # use for AD","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Then define a structure to hold the data: observables, covariates, and the degrees of freedom for the prior.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"\"\"\"\nLinear regression model ``y ∼ Xβ + ϵ``, where ``ϵ ∼ N(0, σ²)`` IID.\n\nFlat prior for `β`, half-T for `σ`.\n\"\"\"\nstruct LinearRegressionProblem{TY <: AbstractVector, TX <: AbstractMatrix,\n                               Tν <: Real}\n    \"Observations.\"\n    y::TY\n    \"Covariates\"\n    X::TX\n    \"Degrees of freedom for prior.\"\n    ν::Tν\nend","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Then make the type callable with the parameters as a single argument.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"function (problem::LinearRegressionProblem)(θ)\n    @unpack y, X, ν = problem   # extract the data\n    @unpack β, σ = θ            # works on the named tuple too\n    loglikelihood(Normal(0, σ), y .- X*β) + logpdf(TDist(ν), σ)\nend","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"We should test this, also, this would be a good place to benchmark and optimize more complicated problems.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"N = 100\nX = hcat(ones(N), randn(N, 2));\nβ = [1.0, 2.0, -1.0]\nσ = 0.5\ny = X*β .+ randn(N) .* σ;\np = LinearRegressionProblem(y, X, 1.0);\np((β = β, σ = σ))","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"For this problem, we write a function to return the transformation (as it varies with the number of covariates).","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"function problem_transformation(p::LinearRegressionProblem)\n    as((β = as(Array, size(p.X, 2)), σ = asℝ₊))\nend","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Wrap the problem with a transformation, then use ForwardDiff for the gradient.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"t = problem_transformation(p)\nP = TransformedLogDensity(t, p)\n∇P = ADgradient(:ForwardDiff, P);\nnothing #hide","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Finally, we sample from the posterior. chain holds the chain (positions and diagnostic information), while the second returned value is the tuned sampler which would allow continuation of sampling.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"results = mcmc_with_warmup(Random.GLOBAL_RNG, ∇P, 1000);\nnothing #hide","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"We use the transformation to obtain the posterior from the chain.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"posterior = transform.(t, results.chain);\nnothing #hide","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Extract the parameter posterior means: β,","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"posterior_β = mean(first, posterior)","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"then σ:","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"posterior_σ = mean(last, posterior)","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Effective sample sizes (of untransformed draws)","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"ess = vec(mapslices(effective_sample_size,\n                    DynamicHMC.position_matrix(results.chain);\n                    dims = 2))","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"NUTS-specific statistics","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"summarize_tree_statistics(results.tree_statistics)","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"EditURL = \"https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_logistic_regression.jl\"","category":"page"},{"location":"example_logistic_regression/#Logistic-regression","page":"Logistic regression","title":"Logistic regression","text":"","category":"section"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"using TransformVariables, LogDensityProblems, DynamicHMC, DynamicHMC.Diagnostics,\n    Parameters, Statistics, Random, Distributions, StatsFuns, TransformedLogDensities\nusing MCMCDiagnostics\nimport ForwardDiff              # use for AD\n\n\"\"\"\nLogistic regression.\n\nFor each draw, ``logit(Pr(yᵢ == 1)) ∼ Xᵢ β``. Uses a `β ∼ Normal(0, σ)` prior.\n\n`X` is supposed to include the `1`s for the intercept.\n\"\"\"\nstruct LogisticRegression{Ty, TX, Tσ}\n    y::Ty\n    X::TX\n    σ::Tσ\nend\n\nfunction (problem::LogisticRegression)(θ)\n    @unpack y, X, σ = problem\n    @unpack β = θ\n    loglik = sum(logpdf.(Bernoulli.(logistic.(X*β)), y))\n    logpri = sum(logpdf.(Ref(Normal(0, σ)), β))\n    loglik + logpri\nend","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Make up parameters, generate data using random draws.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"N = 1000\nβ = [1.0, 2.0]\nX = hcat(ones(N), randn(N))\ny = rand.(Bernoulli.(logistic.(X*β)));\nnothing #hide","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Create a problem, apply a transformation, then use automatic differentiation.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"p = LogisticRegression(y, X, 10.0)   # data and (vague) priors\nt = as((β = as(Array, length(β)), )) # identity transformation, just to get the dimension\nP = TransformedLogDensity(t, p)      # transformed\n∇P = ADgradient(:ForwardDiff, P)","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Sample using NUTS, random starting point.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"results = mcmc_with_warmup(Random.GLOBAL_RNG, ∇P, 1000);\nnothing #hide","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Extract the posterior. (Here the transformation was not really necessary).","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"β_posterior = first.(transform.(t, results.chain));\nnothing #hide","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Check that we recover the parameters.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"mean(β_posterior)","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Quantiles","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"qs = [0.05, 0.25, 0.5, 0.75, 0.95]\nquantile(first.(β_posterior), qs)\n\nquantile(last.(β_posterior), qs)","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Check that mixing is good.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"ess = vec(mapslices(effective_sample_size, reduce(hcat, β_posterior); dims = 2))","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"EditURL = \"https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_multinomial_logistic_regression.jl\"","category":"page"},{"location":"example_multinomial_logistic_regression/#Multinomial-logistic-regression","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"","category":"section"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"using TransformVariables, LogDensityProblems, DynamicHMC, DynamicHMC.Diagnostics,\n    TransformedLogDensities,  Parameters, Statistics, Random, Distributions\nusing MCMCDiagnostics\nusing LogExpFunctions: softmax\nimport ForwardDiff # use for automatic differentiation (AD)\n\n\"\"\"\nMultinomial logistic regression.\n\nFor each draw, ``Pr(yᵢ) ∼ softmax(Xᵢ β)``. Uses a `β ∼ MultivariateNormal(0, σI)` prior.\n\n`X` is supposed to include the `1`s for the intercept.\n\"\"\"\nstruct MultinomialLogisticRegression{Ty, TX, Tσ}\n    y::Ty\n    X::TX\n    σ::Tσ\nend\n\nfunction (problem::MultinomialLogisticRegression)(θ)\n    @unpack y, X, σ = problem\n    @unpack β = θ\n    num_rows, num_covariates = size(X)\n    num_classes = size(β, 2) + 1\n    η = X * hcat(zeros(num_covariates), β) # the first column of all zeros corresponds to the base class\n    μ = softmax(η; dims=2)\n    loglik = sum([logpdf(Multinomial(1, μ[i, :]), y[i, :]) for i = 1:num_rows])\n    logpri = sum([logpdf(MultivariateNormal(num_classes - 1, σ), β[i, :]) for i = 1:num_covariates])\n    return loglik + logpri\nend","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Make up parameters, generate data using random draws.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"N = 10_000","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"There are two covariates. The first one (the column of all ones) is the intercept.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"X = hcat(ones(N), randn(N));\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"If we have C classes, then for each covariate we need (C - 1) coefficients. we consider the first class to be the \"base class\" and then for each of the other classes, we have a coefficient comparing that class to the base class In this example, we have four classes, so we need three coefficients for each covariate. There are two covariates, so we will have six coefficients in total. the rows of β correspond to the covariates e.g. the first row of β corresponds to the first covariate (the intercept) e.g. the second row of β corresponds to the second covariate the columns of β correspond to classes recall that we set the first class as our \"base class\" then the jth column of β contains the coefficients comparing the (j+1) class against the first class e.g. the first column of β contains coefficients comparing the second class against the first class e.g. the second column of β contains coefficients comparing the third class against the first class e.g. the third column of β contains coefficients comparing the fourth class against the first class","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"β_true = [1.0 2.0 3.0; 4.0 5.0 6.0]\nη = X * hcat(zeros(2), β_true);\nμ = softmax(η; dims=2);\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"y has N rows and C columns the rows of y correspond to observations the columns of y correspond to classes","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"y = vcat([rand(Multinomial(1, μ[i,:]))' for i in 1:N]...);\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Create a problem, apply a transformation, then use automatic differentiation.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"p = MultinomialLogisticRegression(y, X, 100.0) # data and (vague) priors\nt = as((β = as(Array, size(β_true)), )) # identity transformation, just to get the dimension\nP = TransformedLogDensity(t, p) # transformed\n∇P = ADgradient(:ForwardDiff, P) # use ForwardDiff for automatic differentiation (AD)","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Sample using NUTS, random starting point.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"results = mcmc_with_warmup(Random.GLOBAL_RNG, ∇P, 1_000);\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Extract the posterior. (Here the transformation was not really necessary).","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"β_posterior = first.(transform.(t, results.chain));\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Check that we recover the parameters.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"mean(β_posterior)\n\nfunction _median(x)\n\tn = length(x)\n\tresult = similar(first(x))\n\tfor i in eachindex(result)\n\t\tresult[i] = median([x[j][i] for j = 1:n])\n\tend\n\treturn result\nend\n\n_median(β_posterior)","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Quantiles","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"qs = [0.05, 0.25, 0.5, 0.75, 0.95]\nquantile([β_posterior[i][1, 1] for i in 1:length(β_posterior)], qs)\nquantile([β_posterior[i][1, 2] for i in 1:length(β_posterior)], qs)\nquantile([β_posterior[i][1, 3] for i in 1:length(β_posterior)], qs)\nquantile([β_posterior[i][2, 1] for i in 1:length(β_posterior)], qs)\nquantile([β_posterior[i][2, 2] for i in 1:length(β_posterior)], qs)\nquantile([β_posterior[i][2, 3] for i in 1:length(β_posterior)], qs)","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Check that mixing is good.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"ess = vec(mapslices(effective_sample_size, reduce(hcat, [vec(a) for a in β_posterior]); dims = 2))","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"EditURL = \"https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_independent_bernoulli.jl\"","category":"page"},{"location":"example_independent_bernoulli/#Estimate-Bernoulli-draws-probabilility","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"","category":"section"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"We estimate a simple model of n independent Bernoulli draws, with probability α. First, we load the packages we use.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"using TransformVariables, LogDensityProblems, DynamicHMC, DynamicHMC.Diagnostics,\n    TransformedLogDensities, Parameters, Statistics, Random\nusing MCMCDiagnostics\nimport ForwardDiff              # use for AD","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Then define a structure to hold the data. For this model, the number of draws equal to 1 is a sufficient statistic.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"\"\"\"\nToy problem using a Bernoulli distribution.\n\nWe model `n` independent draws from a ``Bernoulli(α)`` distribution.\n\"\"\"\nstruct BernoulliProblem\n    \"Total number of draws in the data.\"\n    n::Int\n    \"Number of draws `==1` in the data\"\n    s::Int\nend","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Then make the type callable with the parameters as a single argument.  We use decomposition in the arguments, but it could be done inside the function, too.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"function (problem::BernoulliProblem)(θ)\n    @unpack α = θ               # extract the parameters\n    @unpack n, s = problem      # extract the data\n    # log likelihood: the constant log(combinations(n, s)) term\n    # has been dropped since it is irrelevant to sampling.\n    s * log(α) + (n-s) * log(1-α)\nend","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"We should test this, also, this would be a good place to benchmark and optimize more complicated problems.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"p = BernoulliProblem(20, 10)\np((α = 0.5, ))","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Recall that we need to","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"transform from ℝ to the valid parameter domain (0,1) for more efficient sampling, and\ncalculate the derivatives for this transformed mapping.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"The helper packages TransformVariables and LogDensityProblems take care of this. We use a flat prior (the default, omitted)","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"t = as((α = as𝕀,))\nP = TransformedLogDensity(t, p)\n∇P = ADgradient(:ForwardDiff, P);\nnothing #hide","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Finally, we sample from the posterior. chain holds the chain (positions and diagnostic information), while the second returned value is the tuned sampler which would allow continuation of sampling.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"results = mcmc_with_warmup(Random.GLOBAL_RNG, ∇P, 1000)","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"To get the posterior for α, we need to use get_position and then transform","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"posterior = transform.(t, results.chain);\nnothing #hide","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Extract the parameter.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"posterior_α = first.(posterior);\nnothing #hide","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"check the mean","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"mean(posterior_α)","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"check the effective sample size","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"ess_α = effective_sample_size(posterior_α)","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"NUTS-specific statistics","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"summarize_tree_statistics(results.tree_statistics)","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"This are automatically generated pages from DynamicHMCExamples.jl. Each page is for one example problem, you can study the source directly in the package repository.","category":"page"}]
}
