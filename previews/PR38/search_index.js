var documenterSearchIndex = {"docs":
[{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"EditURL = \"https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_linear_regression.jl\"","category":"page"},{"location":"example_linear_regression/#Linear-regression","page":"Linear regression","title":"Linear regression","text":"","category":"section"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"We estimate simple linear regression model with a half-T prior. First, we load the packages we use.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"First, we import DynamicHMC and related libraries,","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"using TransformVariables, LogDensityProblems, DynamicHMC, TransformedLogDensities","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"then some packages that help code the log posterior,","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"using Parameters, Statistics, Random, Distributions, LinearAlgebra","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"then diagnostic and benchmark tools,","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"using MCMCDiagnosticTools, DynamicHMC.Diagnostics, BenchmarkTools","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"and use ForwardDiff for AD since the dimensions is small.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"import ForwardDiff","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Then define a structure to hold the data: observables, covariates, and the degrees of freedom for the prior.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"\"\"\"\nLinear regression model ``y ‚àº XŒ≤ + œµ``, where ``œµ ‚àº N(0, œÉ¬≤)`` IID.\n\nWeakly informative prior for `Œ≤`, half-T for `œÉ`.\n\"\"\"\nstruct LinearRegressionProblem{TY <: AbstractVector, TX <: AbstractMatrix,\n                               TŒΩ <: Real}\n    \"Observations.\"\n    y::TY\n    \"Covariates\"\n    X::TX\n    \"Degrees of freedom for prior.\"\n    ŒΩ::TŒΩ\nend","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Then make the type callable with the parameters as a single argument.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"function (problem::LinearRegressionProblem)(Œ∏)\n    @unpack y, X, ŒΩ = problem   # extract the data\n    @unpack Œ≤, œÉ = Œ∏            # works on the named tuple too\n    œµ_distribution = Normal(0, œÉ) # the error term\n    ‚Ñì_error = mapreduce((y, x) -> logpdf(œµ_distribution, y - dot(x, Œ≤)), +,\n                        y, eachrow(X))    # likelihood for error\n    ‚Ñì_œÉ = logpdf(TDist(ŒΩ), œÉ)             # prior for œÉ\n    ‚Ñì_Œ≤ = loglikelihood(Normal(0, 10), Œ≤) # prior for Œ≤\n    ‚Ñì_error + ‚Ñì_œÉ + ‚Ñì_Œ≤\nend","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Make up random data and test the function runs.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"N = 100\nX = hcat(ones(N), randn(N, 2));\nŒ≤ = [1.0, 2.0, -1.0]\nœÉ = 0.5\ny = X*Œ≤ .+ randn(N) .* œÉ;\np = LinearRegressionProblem(y, X, 1.0);\np((Œ≤ = Œ≤, œÉ = œÉ))","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"It is usually a good idea to benchmark and optimize your log posterior code at this stage. Above, we have carefully optimized allocations away using mapreduce.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"@btime p((Œ≤ = $Œ≤, œÉ = $œÉ))","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"For this problem, we write a function to return the transformation (as it varies with the number of covariates).","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"function problem_transformation(p::LinearRegressionProblem)\n    as((Œ≤ = as(Array, size(p.X, 2)), œÉ = as‚Ñù‚Çä))\nend","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Wrap the problem with a transformation, then use ForwardDiff for the gradient.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"t = problem_transformation(p)\nP = TransformedLogDensity(t, p)\n‚àáP = ADgradient(:ForwardDiff, P);\nnothing #hide","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Finally, we sample from the posterior. chain holds the chain (positions and diagnostic information), while the second returned value is the tuned sampler which would allow continuation of sampling.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"results = map(_ -> mcmc_with_warmup(Random.default_rng(), ‚àáP, 1000), 1:5)","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"We use the transformation to obtain the posterior from the chain.","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"posterior = transform.(t, eachcol(pool_posterior_matrices(results)));\nnothing #hide","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Extract the parameter posterior means: Œ≤,","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"posterior_Œ≤ = mean(first, posterior)","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"then œÉ:","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"posterior_œÉ = mean(last, posterior)","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"Effective sample sizes (of untransformed draws)","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"ess, RÃÇ = ess_rhat(stack_posterior_matrices(results))","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"summarize NUTS-specific statistics of all chains","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"summarize_tree_statistics(mapreduce(x -> x.tree_statistics, vcat, results))","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"","category":"page"},{"location":"example_linear_regression/","page":"Linear regression","title":"Linear regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"EditURL = \"https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_logistic_regression.jl\"","category":"page"},{"location":"example_logistic_regression/#Logistic-regression","page":"Logistic regression","title":"Logistic regression","text":"","category":"section"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"First, we import DynamicHMC and related libraries,","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"using TransformVariables, LogDensityProblems, DynamicHMC, TransformedLogDensities","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"then some packages that help code the log posterior,","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"using Parameters, Statistics, Random, Distributions, LinearAlgebra, StatsFuns, LogExpFunctions","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"then diagnostic and benchmark tools,","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"using MCMCDiagnosticTools, BenchmarkTools","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"and use ForwardDiff for AD since the dimensions is small.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"import ForwardDiff\n\n\"\"\"\nLogistic regression.\n\nFor each draw, ``logit(Pr(y·µ¢ == 1)) ‚àº X·µ¢ Œ≤``. Uses a `Œ≤ ‚àº Normal(0, œÉ)` prior.\n\n`X` is supposed to include the `1`s for the intercept.\n\"\"\"\nstruct LogisticRegression{Ty, TX, TœÉ}\n    y::Ty\n    X::TX\n    œÉ::TœÉ\nend\n\nfunction (problem::LogisticRegression)(Œ∏)\n    @unpack y, X, œÉ = problem\n    @unpack Œ≤ = Œ∏\n    ‚Ñì_y = mapreduce((y, x) -> logpdf(Bernoulli(logistic(dot(x, Œ≤))), y), +, y, eachrow(X))\n    ‚Ñì_Œ≤ =  loglikelihood(Normal(0, œÉ), Œ≤)\n    ‚Ñì_y + ‚Ñì_Œ≤\nend","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Make up parameters, generate data using random draws.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"N = 1000\nŒ≤ = [1.0, 2.0]\nX = hcat(ones(N), randn(N))\ny = rand.(Bernoulli.(logistic.(X*Œ≤)));\nnothing #hide","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Create a problem, apply a transformation, then use automatic differentiation.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"p = LogisticRegression(y, X, 10.0)   # data and (vague) priors\nt = as((Œ≤ = as(Array, length(Œ≤)), )) # identity transformation, just to get the dimension\nP = TransformedLogDensity(t, p)      # transformed\n‚àáP = ADgradient(:ForwardDiff, P)","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Benchmark","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"@btime p((Œ≤ = $Œ≤,))","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Sample using NUTS, random starting point.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"results = map(_ -> mcmc_with_warmup(Random.default_rng(), ‚àáP, 1000), 1:5)","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Extract the posterior. (Here the transformation was not really necessary).","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Œ≤_posterior = first.(transform.(t, eachcol(pool_posterior_matrices(results))))","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Check that we recover the parameters.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"mean(Œ≤_posterior)","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Quantiles","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"qs = [0.05, 0.25, 0.5, 0.75, 0.95]\nquantile(first.(Œ≤_posterior), qs)\n\nquantile(last.(Œ≤_posterior), qs)","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"Check that mixing is good.","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"ess, RÃÇ = ess_rhat(stack_posterior_matrices(results))","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"","category":"page"},{"location":"example_logistic_regression/","page":"Logistic regression","title":"Logistic regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"EditURL = \"https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_multinomial_logistic_regression.jl\"","category":"page"},{"location":"example_multinomial_logistic_regression/#Multinomial-logistic-regression","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"","category":"section"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"using TransformVariables, LogDensityProblems, DynamicHMC, DynamicHMC.Diagnostics,\n    TransformedLogDensities,  Parameters, Statistics, Random, Distributions\nusing MCMCDiagnostics\nusing LogExpFunctions: softmax\nimport ForwardDiff # use for automatic differentiation (AD)\n\n\"\"\"\nMultinomial logistic regression.\n\nFor each draw, ``Pr(y·µ¢) ‚àº softmax(X·µ¢ Œ≤)``. Uses a `Œ≤ ‚àº MultivariateNormal(0, œÉI)` prior.\n\n`X` is supposed to include the `1`s for the intercept.\n\"\"\"\nstruct MultinomialLogisticRegression{Ty, TX, TœÉ}\n    y::Ty\n    X::TX\n    œÉ::TœÉ\nend\n\nfunction (problem::MultinomialLogisticRegression)(Œ∏)\n    @unpack y, X, œÉ = problem\n    @unpack Œ≤ = Œ∏\n    num_rows, num_covariates = size(X)\n    num_classes = size(Œ≤, 2) + 1\n    Œ∑ = X * hcat(zeros(num_covariates), Œ≤) # the first column of all zeros corresponds to the base class\n    Œº = softmax(Œ∑; dims=2)\n    loglik = sum([logpdf(Multinomial(1, Œº[i, :]), y[i, :]) for i = 1:num_rows])\n    logpri = sum([logpdf(MultivariateNormal(num_classes - 1, œÉ), Œ≤[i, :]) for i = 1:num_covariates])\n    return loglik + logpri\nend","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Make up parameters, generate data using random draws.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"N = 10_000","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"There are two covariates. The first one (the column of all ones) is the intercept.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"X = hcat(ones(N), randn(N));\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"If we have C classes, then for each covariate we need (C - 1) coefficients. we consider the first class to be the \"base class\" and then for each of the other classes, we have a coefficient comparing that class to the base class In this example, we have four classes, so we need three coefficients for each covariate. There are two covariates, so we will have six coefficients in total. the rows of Œ≤ correspond to the covariates e.g. the first row of Œ≤ corresponds to the first covariate (the intercept) e.g. the second row of Œ≤ corresponds to the second covariate the columns of Œ≤ correspond to classes recall that we set the first class as our \"base class\" then the jth column of Œ≤ contains the coefficients comparing the (j+1) class against the first class e.g. the first column of Œ≤ contains coefficients comparing the second class against the first class e.g. the second column of Œ≤ contains coefficients comparing the third class against the first class e.g. the third column of Œ≤ contains coefficients comparing the fourth class against the first class","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Œ≤_true = [1.0 2.0 3.0; 4.0 5.0 6.0]\nŒ∑ = X * hcat(zeros(2), Œ≤_true);\nŒº = softmax(Œ∑; dims=2);\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"y has N rows and C columns the rows of y correspond to observations the columns of y correspond to classes","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"y = vcat([rand(Multinomial(1, Œº[i,:]))' for i in 1:N]...);\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Create a problem, apply a transformation, then use automatic differentiation.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"p = MultinomialLogisticRegression(y, X, 100.0) # data and (vague) priors\nt = as((Œ≤ = as(Array, size(Œ≤_true)), )) # identity transformation, just to get the dimension\nP = TransformedLogDensity(t, p) # transformed\n‚àáP = ADgradient(:ForwardDiff, P) # use ForwardDiff for automatic differentiation (AD)","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Sample using NUTS, random starting point.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"results = mcmc_with_warmup(Random.GLOBAL_RNG, ‚àáP, 1_000);\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Extract the posterior. (Here the transformation was not really necessary).","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Œ≤_posterior = first.(transform.(t, results.chain));\nnothing #hide","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Check that we recover the parameters.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"mean(Œ≤_posterior)\n\nfunction _median(x)\n\tn = length(x)\n\tresult = similar(first(x))\n\tfor i in eachindex(result)\n\t\tresult[i] = median([x[j][i] for j = 1:n])\n\tend\n\treturn result\nend\n\n_median(Œ≤_posterior)","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Quantiles","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"qs = [0.05, 0.25, 0.5, 0.75, 0.95]\nquantile([Œ≤_posterior[i][1, 1] for i in 1:length(Œ≤_posterior)], qs)\nquantile([Œ≤_posterior[i][1, 2] for i in 1:length(Œ≤_posterior)], qs)\nquantile([Œ≤_posterior[i][1, 3] for i in 1:length(Œ≤_posterior)], qs)\nquantile([Œ≤_posterior[i][2, 1] for i in 1:length(Œ≤_posterior)], qs)\nquantile([Œ≤_posterior[i][2, 2] for i in 1:length(Œ≤_posterior)], qs)\nquantile([Œ≤_posterior[i][2, 3] for i in 1:length(Œ≤_posterior)], qs)","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"Check that mixing is good.","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"ess = vec(mapslices(effective_sample_size, reduce(hcat, [vec(a) for a in Œ≤_posterior]); dims = 2))","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"","category":"page"},{"location":"example_multinomial_logistic_regression/","page":"Multinomial logistic regression","title":"Multinomial logistic regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"EditURL = \"https://github.com/tpapp/DynamicHMCExamples.jl/blob/master/src/example_independent_bernoulli.jl\"","category":"page"},{"location":"example_independent_bernoulli/#Estimate-Bernoulli-draws-probabilility","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"","category":"section"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"We estimate a simple model of n independent Bernoulli draws, with probability Œ±. First, we load the packages we use.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"First, we import DynamicHMC and related libraries,","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"using TransformVariables, LogDensityProblems, DynamicHMC, TransformedLogDensities","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"then some packages that help code the log posterior,","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"using Parameters, Statistics, Random, Distributions, LinearAlgebra","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"then diagnostic tools,","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"using MCMCDiagnosticTools, DynamicHMC.Diagnostics","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"and use ForwardDiff for AD since the dimensions is small.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"import ForwardDiff","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Then define a structure to hold the data. For this model, the number of draws equal to 1 is a sufficient statistic.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"\"\"\"\nToy problem using a Bernoulli distribution.\n\nWe model `n` independent draws from a ``Bernoulli(Œ±)`` distribution.\n\"\"\"\nstruct BernoulliProblem\n    \"Total number of draws in the data.\"\n    n::Int\n    \"Number of draws `==1` in the data\"\n    s::Int\nend","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Then make the type callable with the parameters as a single argument.  We use decomposition in the arguments, but it could be done inside the function, too.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"function (problem::BernoulliProblem)(Œ∏)\n    @unpack Œ± = Œ∏               # extract the parameters\n    @unpack n, s = problem      # extract the data\n    # log likelihood: the constant log(combinations(n, s)) term\n    # has been dropped since it is irrelevant for posterior sampling.\n    s * log(Œ±) + (n-s) * log(1-Œ±)\nend","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"We should test this, also, this would be a good place to benchmark and optimize more complicated problems.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"p = BernoulliProblem(20, 10)\np((Œ± = 0.5, ))","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Recall that we need to","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"transform from ‚Ñù to the valid parameter domain (0,1) for more efficient sampling, and\ncalculate the derivatives for this transformed mapping.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"The helper packages TransformVariables and LogDensityProblems take care of this. We use a flat prior.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"t = as((Œ± = asùïÄ,))\nP = TransformedLogDensity(t, p)\n‚àáP = ADgradient(:ForwardDiff, P);\nnothing #hide","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Finally, we sample from the posterior. The returned value the posterior matrix, diagnostic information, and the tuned sampler which would allow continuation of sampling.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"results = [mcmc_with_warmup(Random.default_rng(), ‚àáP, 1000) for _ in 1:5]","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"To get the posterior for Œ±, we need to use the columns of the posterior_matrix and then transform","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"posterior = transform.(t, eachcol(pool_posterior_matrices(results)));\nnothing #hide","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"Extract the parameter.","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"posterior_Œ± = first.(posterior);\nnothing #hide","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"check the mean","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"mean(posterior_Œ±)","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"check the effective sample size","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"ess, RÃÇ = ess_rhat(stack_posterior_matrices(results))","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"NUTS-specific statistics of the first chain","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"summarize_tree_statistics(results[1].tree_statistics)","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"","category":"page"},{"location":"example_independent_bernoulli/","page":"Estimate Bernoulli draws probabilility","title":"Estimate Bernoulli draws probabilility","text":"This page was generated using Literate.jl.","category":"page"},{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"This are automatically generated pages from DynamicHMCExamples.jl. Each page is for one example problem, you can study the source directly in the package repository.","category":"page"}]
}
